{"cells":[{"cell_type":"markdown","source":["# Importing Libraries"],"metadata":{"id":"ald20DL4GViT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_fy9ovd9kK7O","outputId":"f1ffd63b-0e28-4925-ef2a-467837a89bd5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/manu/Documents/SU_CHATBOT/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import json\n","import csv\n","import psycopg2\n","from sentence_transformers import SentenceTransformer\n","from groq import Groq"]},{"cell_type":"markdown","source":["# Creating Embedding of Questions\n","    SentenceTransformer('multi-qa-mpnet-base-dot-v1')"],"metadata":{"id":"Az24p7InGdSb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaxBmelbkK7S"},"outputs":[],"source":["model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6By_cHCkK7U"},"outputs":[],"source":["def create_embedding(csv_file):\n","\n","    # Load the CSV file\n","    data = pd.read_csv(csv_file)\n","\n","    # Generate embeddings for the questions\n","    data['embedding'] = data['question'].apply(lambda x: model.encode(x).tolist())\n","\n","    print(\"Embedding Created\")\n","\n","    # Return the dataFrame with embedding\n","    return data\n"]},{"cell_type":"markdown","source":["# Storing Embedding in tha Database\n","    PgVector"],"metadata":{"id":"1iFxDkYFG3S5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PArMrE1xkK7Y"},"outputs":[],"source":["def get_db_connection():\n","    # Connect to your PostgreSQL database\n","    conn = psycopg2.connect(\n","        dbname=\"chatbot\",\n","        user=\"postgres\",\n","        password=\"1234\",\n","        host=\"localhost\",  # Or the IP address of your PostgreSQL server\n","        port=\"5432\"        # Default port for PostgreSQL\n","    )\n","    return conn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWbhPGElkK7a"},"outputs":[],"source":["def insert_data(data):\n","    conn = get_db_connection()\n","    cur = conn.cursor()\n","\n","# Insert data into the PostgreSQL table\n","    for index, row in data.iterrows():\n","        question = row['question']\n","        answer = row['answer']\n","        embedding = row['embedding']  # This is a list of floats\n","\n","\n","        insert_query = \"\"\"\n","    INSERT INTO questions (question, answer, embedding)\n","    VALUES (%s, %s, %s::vector)\n","    \"\"\"\n","\n","        cur.execute(insert_query, (question, answer, embedding))\n","\n","# Commit changes and close the connection\n","    conn.commit()\n","    cur.close()\n","    conn.close()\n","\n","    print(\"Data inserted successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8M1TKphdkK7b","outputId":"f447d8bf-a9ae-43d6-f8e2-051ff54a7bb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Embedding Created\n","Embedding Created\n","Embedding Created\n"]}],"source":["data1 = create_embedding(\"CuratedDataSet.csv\")\n","data2 =  create_embedding(\"ShravanDataSet.csv\")\n","data3 = create_embedding(\"Extra.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-w09aiJnkK7d","outputId":"805bc020-441a-4831-d44c-be9d9ad618f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data inserted successfully!\n","Data inserted successfully!\n","Data inserted successfully!\n"]}],"source":["insert_data(data1)\n","insert_data(data2)\n","insert_data(data3)"]},{"cell_type":"markdown","source":["# Function for answer retrival"],"metadata":{"id":"Saf1SDqqHJPh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnDPBeZ6kK7f"},"outputs":[],"source":["def top_answer(query, model, conn, top_k=10):\n","    # Generate embedding for the input query\n","    query_embedding = model.encode(query, convert_to_tensor=False)\n","\n","    # Convert query_embedding to string format suitable for PostgreSQL\n","    embedding_str = '[' + ','.join(map(str, query_embedding)) + ']'\n","\n","    cursor = conn.cursor()\n","\n","    # Perform similarity search using pgvector's <=> operator for cosine similarity\n","    cursor.execute(\"\"\"\n","    SELECT id, question, answer, embedding\n","    FROM questions\n","    ORDER BY embedding <=> %s\n","    LIMIT %s\n","    \"\"\", (embedding_str, top_k))\n","\n","    rows = cursor.fetchall()\n","\n","    retrieved_responses= []\n","    for row in rows:\n","        retrieved_responses.append(row[2])  # Answer column\n","\n","    cursor.close()\n","\n","    return retrieved_responses\n"]},{"cell_type":"markdown","source":["# Lamma Answers Generations\n","    Using Groq API"],"metadata":{"id":"6I7gXj-QHac0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUYzzmQXkK7g"},"outputs":[],"source":["grok_api_key = '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'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4mI_6yGkK7h"},"outputs":[],"source":["# Get this from Groq Documentation\n","def GroqChat(question):\n","    client = Groq(\n","        api_key=grok_api_key,\n","\n","    )\n","\n","    chat_completion = client.chat.completions.create(\n","        messages=[\n","            {\n","                \"role\": \"user\",\n","                \"content\": question,\n","            }\n","        ],\n","            model = \"llama-3.1-70b-versatile\"\n","    )\n","\n","    cleaned_json_string = chat_completion.choices[0].message.content\n","\n","    json_str = re.sub(r'}\\s*{', '}, {', cleaned_json_string)\n","    return json_str"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZBlEi7lkK7h"},"outputs":[],"source":["def generate_answer(query, retrieved_responses):\n","    result = []\n","    if not retrieved_responses:\n","        return \"We are unable to response for this query.\"\n","\n","    context = \"\\n\".join(retrieved_responses)\n","    result.append(context)\n","\n","    prompt = f\"Answer the following query based solely on the provided context. Do not include any information from outside the context, and do not mention that a context is provided. If the context does not address the query, respond with ' We're currently in the process of collecting data to provide a comprehensive answer. Thank you for your patience as we work on this. ' If the query includes greetings like 'Good morning' or 'Good evening', respond accordingly. Query: {query} Context: {context}\"\n","\n","    groq_answer = GroqChat(prompt)\n","    result.append(groq_answer)\n","\n","    return result\n"]},{"cell_type":"markdown","source":["# Driver Code"],"metadata":{"id":"N2HvbtiPHlGI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdYCxwRskK7i","outputId":"003f7c4a-9859-4a7e-8b1f-2b1e398ccd3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["You:  highest package till now ?\n","Llama Answer:  We're currently in the process of collecting data to provide a comprehensive answer. Thank you for your patience as we work on this.\n","\n","You:  highets placement ?\n","Llama Answer:  We're currently in the process of collecting data to provide a comprehensive answer on highest placement figures.Placement statistics will be available once the first batch of students graduates. However, students are currently gaining experience through internships at notable startups with competitive stipends.\n","\n","You:  highest package till now from siatre university ?\n","Llama Answer:  We're currently in the process of collecting data to provide a comprehensive answer. Thank you for your patience as we work on this.\n","\n"]}],"source":["if __name__ == \"__main__\":\n","\n","    # model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n","\n","    # Establish DB connection\n","    conn = get_db_connection()\n","\n","    while True:\n","        query = input(\"Enter your query here: \")\n","\n","        if query == '':\n","            continue\n","\n","        if query.lower() == \"stop\":\n","            break\n","\n","        retrieved_responses = list(set(top_answer(query, model, conn)))\n","        generated_answer = generate_answer(query, retrieved_responses)\n","        print('You: ',query)\n","        print(\"Answer: \", generated_answer[1])\n","\n","        print()\n","\n","    conn.close()  # Close DB connection when done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TndJJ-ihkK7l"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"collapsed_sections":["ald20DL4GViT","Az24p7InGdSb","1iFxDkYFG3S5","Saf1SDqqHJPh","6I7gXj-QHac0","N2HvbtiPHlGI"]}},"nbformat":4,"nbformat_minor":0}